// Copyright (C) 2020-2023 CERN and UCLouvain.
// Licensed under the GNU Lesser General Public License (version 3 or later).
// Created by: A. Valassi (Nov 2020) for the MG5aMC CUDACPP plugin.
// Further modified by: A. Valassi, Z. Wettersten (2020-2023) for the MG5aMC CUDACPP plugin.

#ifndef MGONGPUVECTORS_H
#define MGONGPUVECTORS_H 1

#include "mgOnGpuCxtypes.h"
#include "mgOnGpuFptypes.h"

#include <iostream>

//==========================================================================

//------------------------------
// Vector types - C++
//------------------------------

#ifdef __clang__
// If set: return a pair of (fptype&, fptype&) by non-const reference in cxtype_v::operator[]
// This is forbidden in clang ("non-const reference cannot bind to vector element")
// See also https://stackoverflow.com/questions/26554829
//#define MGONGPU_HAS_CPPCXTYPEV_BRK 1 // clang test (compilation fails also on clang 12.0, issue #182)
#undef MGONGPU_HAS_CPPCXTYPEV_BRK // clang default
#elif defined __INTEL_COMPILER
//#define MGONGPU_HAS_CPPCXTYPEV_BRK 1 // icc default?
#undef MGONGPU_HAS_CPPCXTYPEV_BRK // icc test
#else
#define MGONGPU_HAS_CPPCXTYPEV_BRK 1 // gcc default
//#undef MGONGPU_HAS_CPPCXTYPEV_BRK // gcc test (very slightly slower? issue #172)
#endif

namespace mgOnGpu /* clang-format off */
{
#ifdef MGONGPU_CPPSIMD

  const int neppV = MGONGPU_CPPSIMD;

  // SANITY CHECK: cppAlign must be a multiple of neppV * sizeof(fptype)
  static_assert( mgOnGpu::cppAlign % ( neppV * sizeof( fptype ) ) == 0 );

  // SANITY CHECK: check that neppV is a power of two
  static_assert( ispoweroftwo( neppV ), "neppV is not a power of 2" );

  // --- Type definition (using vector compiler extensions: need -march=...)
  // For gcc: https://gcc.gnu.org/onlinedocs/gcc/Vector-Extensions.html
  // For clang: https://clang.llvm.org/docs/LanguageExtensions.html#vectors-and-extended-vectors
#ifdef __clang__
  typedef fptype fptype_v __attribute__( ( ext_vector_type( neppV ) ) ); // RRRR
#else
  typedef fptype fptype_v __attribute__( ( vector_size( neppV * sizeof( fptype ) ) ) ); // RRRR
#endif

  // Mixed fptypes #537: float for color algebra and double elsewhere
#if defined MGONGPU_FPTYPE_DOUBLE and defined MGONGPU_FPTYPE2_FLOAT
  const int neppV2 = MGONGPU_CPPSIMD * 2;
  static_assert( mgOnGpu::cppAlign % ( neppV2 * sizeof( fptype2 ) ) == 0 );
  static_assert( ispoweroftwo( neppV2 ), "neppV2 is not a power of 2" );
#ifdef __clang__
  typedef fptype2 fptype2_v __attribute__( ( ext_vector_type( neppV2 ) ) ); // RRRRRRRR
#else
  typedef fptype2 fptype2_v __attribute__( ( vector_size( neppV2 * sizeof( fptype2 ) ) ) ); // RRRRRRRR
#endif
#else
  typedef fptype_v fptype2_v;
#endif

  // --- Type definition (using vector compiler extensions: need -march=...)
  class cxtype_v // no need for "class alignas(2*sizeof(fptype_v)) cxtype_v"
  {
  public:
    // Array initialization: zero-out as "{0}" (C and C++) or as "{}" (C++ only)
    // See https://en.cppreference.com/w/c/language/array_initialization#Notes
    cxtype_v() : m_real{ 0 }, m_imag{ 0 } {} // RRRR=0000 IIII=0000
    cxtype_v( const cxtype_v& ) = default;
    cxtype_v( cxtype_v&& ) = default;
    cxtype_v( const fptype_v& r, const fptype_v& i ) : m_real( r ), m_imag( i ) {}
    cxtype_v( const fptype_v& r ) : m_real( r ), m_imag{ 0 } {} // IIII=0000
    cxtype_v& operator=( const cxtype_v& ) = default;
    cxtype_v& operator=( cxtype_v&& ) = default;
    cxtype_v& operator+=( const cxtype_v& c ) { m_real += c.real(); m_imag += c.imag(); return *this; }
    cxtype_v& operator-=( const cxtype_v& c ) { m_real -= c.real(); m_imag -= c.imag(); return *this; }
#ifdef MGONGPU_HAS_CPPCXTYPEV_BRK
    // NB: THIS IS THE FUNDAMENTAL DIFFERENCE BETWEEN MGONGPU_HAS_CPPCXTYPEV_BRK DEFINED AND NOT DEFINED
    // NB: the alternative "clang" implementation is simpler: it simply does not have any bracket operator[]
    // NB: ** do NOT implement operator[] to return a value: it does not fail the build (why?) and gives unexpected results! **
    cxtype_ref operator[]( size_t i ) const { return cxtype_ref( m_real[i], m_imag[i] ); }
#endif
    const fptype_v& real() const { return m_real; }
    const fptype_v& imag() const { return m_imag; }
  private:
    fptype_v m_real, m_imag; // RRRRIIII
  };

  // --- Type definition (using vector compiler extensions: need -march=...)
#ifdef __clang__ // https://clang.llvm.org/docs/LanguageExtensions.html#vectors-and-extended-vectors
#if defined MGONGPU_FPTYPE_DOUBLE
  typedef long int bool_v __attribute__( ( ext_vector_type( neppV ) ) ); // bbbb
#elif defined MGONGPU_FPTYPE_FLOAT
  typedef int bool_v __attribute__( ( ext_vector_type( neppV ) ) ); // bbbb
#endif
#else // gcc
#if defined MGONGPU_FPTYPE_DOUBLE
  typedef long int bool_v __attribute__( ( vector_size( neppV * sizeof( long int ) ) ) ); // bbbb
#elif defined MGONGPU_FPTYPE_FLOAT
  typedef int bool_v __attribute__( ( vector_size( neppV * sizeof( int ) ) ) ); // bbbb
#endif
#endif

#else // i.e #ifndef MGONGPU_CPPSIMD (this includes #ifdef __CUDACC__)

  const int neppV = 1;

#endif // #ifdef MGONGPU_CPPSIMD

} /* clang-format on */

//--------------------------------------------------------------------------

// Expose typedefs outside the namespace
using mgOnGpu::neppV;
#ifdef MGONGPU_CPPSIMD
using mgOnGpu::fptype_v;
using mgOnGpu::fptype2_v;
using mgOnGpu::cxtype_v;
using mgOnGpu::bool_v;
#endif

//--------------------------------------------------------------------------

#ifndef __CUDACC__

// Printout to stream for user defined types

#ifndef MGONGPU_CPPCXTYPE_CXSMPL // operator<< for cxsmpl has already been defined!
inline std::ostream&
operator<<( std::ostream& out, const cxtype& c )
{
  out << "[" << cxreal( c ) << "," << cximag( c ) << "]";
  //out << cxreal(c) << "+i" << cximag(c);
  return out;
}
#endif

/*
#ifdef MGONGPU_CPPSIMD
inline std::ostream&
operator<<( std::ostream& out, const bool_v& v )
{
  out << "{ " << v[0];
  for ( int i=1; i<neppV; i++ ) out << ", " << (bool)(v[i]);
  out << " }";
  return out;
}
#endif
*/

#ifdef MGONGPU_CPPSIMD
inline std::ostream&
operator<<( std::ostream& out, const fptype_v& v )
{
  out << "{ " << v[0];
  for( int i = 1; i < neppV; i++ ) out << ", " << v[i];
  out << " }";
  return out;
}
#endif

#ifdef MGONGPU_CPPSIMD
inline std::ostream&
operator<<( std::ostream& out, const cxtype_v& v )
{
#ifdef MGONGPU_HAS_CPPCXTYPEV_BRK
  out << "{ " << v[0];
  for( int i = 1; i < neppV; i++ ) out << ", " << v[i];
#else
  out << "{ " << cxmake( v.real()[0], v.imag()[0] );
  for( int i = 1; i < neppV; i++ ) out << ", " << cxmake( v.real()[i], v.imag()[i] );
#endif
  out << " }";
  return out;
}
#endif

//--------------------------------------------------------------------------

/*
// Printout to std::cout for user defined types

inline void print( const fptype& f ) { std::cout << f << std::endl; }

#ifdef MGONGPU_CPPSIMD
inline void print( const fptype_v& v ) { std::cout << v << std::endl; }
#endif

inline void print( const cxtype& c ) { std::cout << c << std::endl; }

#ifdef MGONGPU_CPPSIMD
inline void print( const cxtype_v& v ) { std::cout << v << std::endl; }
#endif
*/

//--------------------------------------------------------------------------

// Functions and operators for fptype_v

#ifdef MGONGPU_CPPSIMD
inline fptype_v
fpsqrt( const fptype_v& v )
{
  // See https://stackoverflow.com/questions/18921049/gcc-vector-extensions-sqrt
  fptype_v out = {}; // avoid warning 'out' may be used uninitialized: see #594
  for( int i = 0; i < neppV; i++ ) out[i] = fpsqrt( v[i] );
  return out;
}
#endif

/*
#ifdef MGONGPU_CPPSIMD
inline fptype_v
fpvmake( const fptype v[neppV] )
{
  fptype_v out = {}; // see #594
  for ( int i=0; i<neppV; i++ ) out[i] = v[i];
  return out;
}
#endif
*/

//--------------------------------------------------------------------------

// Functions and operators for cxtype_v

#ifdef MGONGPU_CPPSIMD

/*
inline cxtype_v
cxvmake( const cxtype c )
{
  cxtype_v out;
  for ( int i=0; i<neppV; i++ ) out[i] = c;
  return out;
}
*/

inline cxtype_v
cxmake( const fptype_v& r, const fptype_v& i )
{
  return cxtype_v( r, i );
}

inline cxtype_v
cxmake( const fptype_v& r, const fptype& i )
{
  //return cxtype_v( r, fptype_v{i} ); // THIS WAS A BUG! #339
  return cxtype_v( r, fptype_v{} + i ); // IIII=0000+i=iiii
}

inline cxtype_v
cxmake( const fptype& r, const fptype_v& i )
{
  //return cxtype_v( fptype_v{r}, i ); // THIS WAS A BUG! #339
  return cxtype_v( fptype_v{} + r, i ); // IIII=0000+r=rrrr
}

inline const fptype_v&
cxreal( const cxtype_v& c )
{
  return c.real(); // returns by reference
}

inline const fptype_v&
cximag( const cxtype_v& c )
{
  return c.imag(); // returns by reference
}

inline const cxtype_v
cxconj( const cxtype_v& c )
{
  return cxtype_v( c.real(), -c.imag() );
}

inline cxtype_v
operator+( const cxtype_v& a, const cxtype_v& b )
{
  return cxtype_v( a.real() + b.real(), a.imag() + b.imag() );
}

inline cxtype_v
operator+( const fptype_v& a, const cxtype_v& b )
{
  return cxtype_v( a + b.real(), b.imag() );
}

inline cxtype_v
operator+( const cxtype_v& a, const fptype_v& b )
{
  return cxtype_v( a.real() + b, a.imag() );
}

inline const cxtype_v&
operator+( const cxtype_v& a )
{
  return a;
}

inline cxtype_v
operator-( const cxtype_v& a, const cxtype_v& b )
{
  return cxtype_v( a.real() - b.real(), a.imag() - b.imag() );
}

inline cxtype_v
operator-( const fptype& a, const cxtype_v& b )
{
  return cxtype_v( a - b.real(), -b.imag() );
}

inline cxtype_v
operator-( const cxtype_v& a )
{
  return 0 - a;
}

inline cxtype_v
operator-( const cxtype_v& a, const fptype& b )
{
  return cxtype_v( a.real() - b, a.imag() );
}

inline cxtype_v
operator-( const fptype_v& a, const cxtype_v& b )
{
  return cxtype_v( a - b.real(), -b.imag() );
}

inline cxtype_v
operator-( const cxtype_v& a, const fptype_v& b )
{
  return cxtype_v( a.real() - b, a.imag() );
}

inline cxtype_v
operator-( const fptype_v& a, const cxtype& b )
{
  return cxtype_v( a - b.real(), fptype_v{} - b.imag() ); // IIII=0000-b.imag()
}

inline cxtype_v
operator*( const cxtype_v& a, const cxtype_v& b )
{
  return cxtype_v( a.real() * b.real() - a.imag() * b.imag(), a.imag() * b.real() + a.real() * b.imag() );
}

inline cxtype_v
operator*( const cxtype& a, const cxtype_v& b )
{
  return cxtype_v( a.real() * b.real() - a.imag() * b.imag(), a.imag() * b.real() + a.real() * b.imag() );
}

inline cxtype_v
operator*( const cxtype_v& a, const cxtype& b )
{
  return cxtype_v( a.real() * b.real() - a.imag() * b.imag(), a.imag() * b.real() + a.real() * b.imag() );
}

inline cxtype_v
operator*( const fptype& a, const cxtype_v& b )
{
  return cxtype_v( a * b.real(), a * b.imag() );
}

inline cxtype_v
operator*( const cxtype_v& a, const fptype& b )
{
  return cxtype_v( a.real() * b, a.imag() * b );
}

inline cxtype_v
operator*( const fptype_v& a, const cxtype_v& b )
{
  return cxtype_v( a * b.real(), a * b.imag() );
}

inline cxtype_v
operator*( const cxtype_v& a, const fptype_v& b )
{
  return cxtype_v( a.real() * b, a.imag() * b );
}

inline cxtype_v
operator*( const fptype_v& a, const cxtype& b )
{
  return cxtype_v( a * b.real(), a * b.imag() );
}

inline cxtype_v
operator*( const cxtype& a, const fptype_v& b )
{
  return cxtype_v( a.real() * b, a.imag() * b );
}

inline cxtype_v
operator/( const cxtype_v& a, const cxtype_v& b )
{
  fptype_v bnorm = b.real() * b.real() + b.imag() * b.imag();
  return cxtype_v( ( a.real() * b.real() + a.imag() * b.imag() ) / bnorm,
                   ( a.imag() * b.real() - a.real() * b.imag() ) / bnorm );
}

inline cxtype_v
operator/( const cxtype& a, const cxtype_v& b )
{
  fptype_v bnorm = b.real() * b.real() + b.imag() * b.imag();
  return cxtype_v( ( cxreal( a ) * b.real() + cximag( a ) * b.imag() ) / bnorm,
                   ( cximag( a ) * b.real() - cxreal( a ) * b.imag() ) / bnorm );
}

inline cxtype_v
operator/( const fptype& a, const cxtype_v& b )
{
  fptype_v bnorm = b.real() * b.real() + b.imag() * b.imag();
  return cxtype_v( ( a * b.real() ) / bnorm, ( -a * b.imag() ) / bnorm );
}

inline cxtype_v
operator/( const cxtype_v& a, const fptype_v& b )
{
  return cxtype_v( a.real() / b, a.imag() / b );
}

inline cxtype_v
operator/( const cxtype_v& a, const fptype& b )
{
  return cxtype_v( a.real() / b, a.imag() / b );
}

#endif // #ifdef MGONGPU_CPPSIMD

//--------------------------------------------------------------------------

// Functions and operators for bool_v (ternary and masks)

#ifdef MGONGPU_CPPSIMD

inline fptype_v
fpternary( const bool_v& mask, const fptype_v& a, const fptype_v& b )
{
  fptype_v out = {}; // see #594
  for( int i = 0; i < neppV; i++ ) out[i] = ( mask[i] ? a[i] : b[i] );
  return out;
}

inline fptype_v
fpternary( const bool_v& mask, const fptype_v& a, const fptype& b )
{
  fptype_v out = {}; // see #594
  for( int i = 0; i < neppV; i++ ) out[i] = ( mask[i] ? a[i] : b );
  return out;
}

inline fptype_v
fpternary( const bool_v& mask, const fptype& a, const fptype_v& b )
{
  fptype_v out = {}; // see #594
  for( int i = 0; i < neppV; i++ ) out[i] = ( mask[i] ? a : b[i] );
  return out;
}

inline fptype_v
fpternary( const bool_v& mask, const fptype& a, const fptype& b )
{
  fptype_v out = {}; // see #594
  for( int i = 0; i < neppV; i++ ) out[i] = ( mask[i] ? a : b );
  return out;
}

inline cxtype_v
cxternary( const bool_v& mask, const cxtype_v& a, const cxtype_v& b )
{
#ifdef MGONGPU_HAS_CPPCXTYPEV_BRK
  cxtype_v out;
  //for( int i = 0; i < neppV; i++ ) out[i] = ( mask[i] ? a[i] : b[i] ); // OLD error-prone depends on "cxtype_ref& operator=( cxtype_ref&& c )"
  for( int i = 0; i < neppV; i++ ) out[i] = cxtype( mask[i] ? a[i] : b[i] );
  return out;
#else
  fptype_v outr = {}; // see #594
  fptype_v outi = {}; // see #594
  for( int i = 0; i < neppV; i++ )
  {
    outr[i] = ( mask[i] ? a.real()[i] : b.real()[i] );
    outi[i] = ( mask[i] ? a.imag()[i] : b.imag()[i] );
  }
  return cxtype_v( outr, outi );
#endif
}

inline cxtype_v
cxternary( const bool_v& mask, const cxtype_v& a, const cxtype& b )
{
#ifdef MGONGPU_HAS_CPPCXTYPEV_BRK
  cxtype_v out;
  for( int i = 0; i < neppV; i++ ) out[i] = ( mask[i] ? a[i] : b );
  return out;
#else
  fptype_v outr = {}; // see #594
  fptype_v outi = {}; // see #594
  for( int i = 0; i < neppV; i++ )
  {
    outr[i] = ( mask[i] ? a.real()[i] : b.real() );
    outi[i] = ( mask[i] ? a.imag()[i] : b.imag() );
  }
  return cxtype_v( outr, outi );
#endif
}

inline cxtype_v
cxternary( const bool_v& mask, const cxtype& a, const cxtype_v& b )
{
#ifdef MGONGPU_HAS_CPPCXTYPEV_BRK
  cxtype_v out;
  for( int i = 0; i < neppV; i++ ) out[i] = ( mask[i] ? a : b[i] );
  return out;
#else
  fptype_v outr = {}; // see #594
  fptype_v outi = {}; // see #594
  for( int i = 0; i < neppV; i++ )
  {
    outr[i] = ( mask[i] ? a.real() : b.real()[i] );
    outi[i] = ( mask[i] ? a.imag() : b.imag()[i] );
  }
  return cxtype_v( outr, outi );
#endif
}

inline cxtype_v
cxternary( const bool_v& mask, const cxtype& a, const cxtype& b )
{
#ifdef MGONGPU_HAS_CPPCXTYPEV_BRK
  cxtype_v out;
  for( int i = 0; i < neppV; i++ ) out[i] = ( mask[i] ? a : b );
  return out;
#else
  fptype_v outr = {}; // see #594
  fptype_v outi = {}; // see #594
  for( int i = 0; i < neppV; i++ )
  {
    outr[i] = ( mask[i] ? a.real() : b.real() );
    outi[i] = ( mask[i] ? a.imag() : b.imag() );
  }
  return cxtype_v( outr, outi );
#endif
}

/*
inline bool
maskor( const bool_v& mask )
{
  bool out = false;
  for ( int i=0; i<neppV; i++ ) out = out || mask[i];
  return out;
}
*/

#else // i.e. #ifndef MGONGPU_CPPSIMD

inline fptype
fpternary( const bool& mask, const fptype& a, const fptype& b )
{
  return ( mask ? a : b );
}

inline cxtype
cxternary( const bool& mask, const cxtype& a, const cxtype& b )
{
  return ( mask ? a : b );
}

/*
inline bool
maskor( const bool& mask )
{
  return mask;
}
*/

#endif // #ifdef MGONGPU_CPPSIMD

//--------------------------------------------------------------------------

// Functions and operators for fptype_v (min/max)

#ifdef MGONGPU_CPPSIMD

inline fptype_v
fpmax( const fptype_v& a, const fptype_v& b )
{
  return fpternary( ( b < a ), a, b );
}

inline fptype_v
fpmax( const fptype_v& a, const fptype& b )
{
  return fpternary( ( b < a ), a, b );
}

/*
inline fptype_v
fpmax( const fptype& a, const fptype_v& b )
{
  return fpternary( ( b < a ), a, b );
}
*/

inline fptype_v
fpmin( const fptype_v& a, const fptype_v& b )
{
  return fpternary( ( a < b ), a, b );
}

/*
inline fptype_v
fpmin( const fptype_v& a, const fptype& b )
{
  return fpternary( ( a < b ), a, b );
}

inline fptype_v
fpmin( const fptype& a, const fptype_v& b )
{
  return fpternary( ( a < b ), a, b );
}
*/

//--------------------------------------------------------------------------

// Vector wrapper over RRRRIIII floating point vectors (cxtype_v_ref)
namespace mgOnGpu /* clang-format off */
{
  // The cxtype_v_ref class (a non-const reference to two fptype_v variables) was originally designed for MemoryAccessCouplings.
  class cxtype_v_ref
  {
  public:
    cxtype_v_ref() = delete;
    cxtype_v_ref( const cxtype_v_ref& ) = delete;
    cxtype_v_ref( cxtype_v_ref&& ) = default; // copy refs
    cxtype_v_ref( fptype_v& r, fptype_v& i ) : m_preal( &r ), m_pimag( &i ) {} // copy refs
    cxtype_v_ref& operator=( const cxtype_v_ref& ) = delete;
    cxtype_v_ref& operator=( cxtype_v_ref&& c ) = delete;
    cxtype_v_ref& operator=( const cxtype_v& c ) { *m_preal = cxreal( c ); *m_pimag = cximag( c ); return *this; } // copy values
    __host__ __device__ operator cxtype_v() const { return cxmake( *m_preal, *m_pimag ); }
  private:
    fptype_v *m_preal, *m_pimag; // RRRRIIII
  };
} /* clang-format on */

#endif // #ifdef MGONGPU_CPPSIMD

//--------------------------------------------------------------------------

// Functions and operators for fptype2_v

#if defined MGONGPU_CPPSIMD and defined MGONGPU_FPTYPE_DOUBLE and defined MGONGPU_FPTYPE2_FLOAT

inline fptype2_v
fpvmerge( const fptype_v& v1, const fptype_v& v2 )
{
  // This code is not very efficient! It makes mixed precision FFV/color not faster than double on C++ (#537).
  // I considered various alternatives, including
  // - in gcc12 and clang, __builtin_shufflevector (works with different vector lengths, BUT the same fptype...)
  // - casting vector(4)double to vector(4)float and then assigning via reinterpret_cast... but how to do the cast?
  // Probably the best solution is intrinsics?
  // - see https://stackoverflow.com/questions/5139363
  // - see https://stackoverflow.com/questions/54518744
  /*
  fptype2_v out;
  for( int ieppV = 0; ieppV < neppV; ieppV++ )
  {
    out[ieppV] = v1[ieppV];
    out[ieppV+neppV] = v2[ieppV];
  }
  return out;
  */
#if MGONGPU_CPPSIMD == 2
  fptype2_v out =
    { (fptype2)v1[0], (fptype2)v1[1], (fptype2)v2[0], (fptype2)v2[1] };
#elif MGONGPU_CPPSIMD == 4
  fptype2_v out =
    { (fptype2)v1[0], (fptype2)v1[1], (fptype2)v1[2], (fptype2)v1[3], (fptype2)v2[0], (fptype2)v2[1], (fptype2)v2[2], (fptype2)v2[3] };
#elif MGONGPU_CPPSIMD == 8
  fptype2_v out =
    { (fptype2)v1[0], (fptype2)v1[1], (fptype2)v1[2], (fptype2)v1[3], (fptype2)v1[4], (fptype2)v1[5], (fptype2)v1[6], (fptype2)v1[7], (fptype2)v2[0], (fptype2)v2[1], (fptype2)v2[2], (fptype2)v2[3], (fptype2)v2[4], (fptype2)v2[5], (fptype2)v2[6], (fptype2)v2[7] };
#endif
  return out;
}

inline fptype_v
fpvsplit0( const fptype2_v& v )
{
  /*
  fptype_v out = {}; // see #594
  for( int ieppV = 0; ieppV < neppV; ieppV++ )
  {
    out[ieppV] = v[ieppV];
  }
  */
#if MGONGPU_CPPSIMD == 2
  fptype_v out =
    { (fptype)v[0], (fptype)v[1] };
#elif MGONGPU_CPPSIMD == 4
  fptype_v out =
    { (fptype)v[0], (fptype)v[1], (fptype)v[2], (fptype)v[3] };
#elif MGONGPU_CPPSIMD == 8
  fptype_v out =
    { (fptype)v[0], (fptype)v[1], (fptype)v[2], (fptype)v[3], (fptype)v[4], (fptype)v[5], (fptype)v[6], (fptype)v[7] };
#endif
  return out;
}

inline fptype_v
fpvsplit1( const fptype2_v& v )
{
  /*
  fptype_v out = {}; // see #594
  for( int ieppV = 0; ieppV < neppV; ieppV++ )
  {
    out[ieppV] = v[ieppV+neppV];
  }
  */
#if MGONGPU_CPPSIMD == 2
  fptype_v out =
    { (fptype)v[2], (fptype)v[3] };
#elif MGONGPU_CPPSIMD == 4
  fptype_v out =
    { (fptype)v[4], (fptype)v[5], (fptype)v[6], (fptype)v[7] };
#elif MGONGPU_CPPSIMD == 8
  fptype_v out =
    { (fptype)v[8], (fptype)v[9], (fptype)v[10], (fptype)v[11], (fptype)v[12], (fptype)v[13], (fptype)v[14], (fptype)v[15] };
#endif
  return out;
}

#endif // #if defined MGONGPU_CPPSIMD and defined MGONGPU_FPTYPE_DOUBLE and defined MGONGPU_FPTYPE2_FLOAT

#endif // #ifndef __CUDACC__

//==========================================================================

#ifdef __CUDACC__

//------------------------------
// Vector types - CUDA
//------------------------------

// Printout to std::cout for user defined types
inline __host__ __device__ void
print( const fptype& f )
{
  printf( "%f\n", f );
}
inline __host__ __device__ void
print( const cxtype& c )
{
  printf( "[%f, %f]\n", cxreal( c ), cximag( c ) );
}

/*
inline __host__ __device__ const cxtype&
cxvmake( const cxtype& c )
{
  return c;
}
*/

inline __host__ __device__ fptype
fpternary( const bool& mask, const fptype& a, const fptype& b )
{
  return ( mask ? a : b );
}

inline __host__ __device__ cxtype
cxternary( const bool& mask, const cxtype& a, const cxtype& b )
{
  return ( mask ? a : b );
}

#endif // #ifdef __CUDACC__

//==========================================================================

// Scalar-or-vector types: scalar in CUDA, vector or scalar in C++
#ifdef __CUDACC__
typedef bool bool_sv;
typedef fptype fptype_sv;
typedef fptype2 fptype2_sv;
typedef cxtype cxtype_sv;
typedef mgOnGpu::cxtype_ref cxtype_sv_ref;
#elif defined MGONGPU_CPPSIMD
typedef bool_v bool_sv;
typedef fptype_v fptype_sv;
typedef fptype2_v fptype2_sv;
typedef cxtype_v cxtype_sv;
typedef mgOnGpu::cxtype_v_ref cxtype_sv_ref;
#else
typedef bool bool_sv;
typedef fptype fptype_sv;
typedef fptype2 fptype2_sv;
typedef cxtype cxtype_sv;
typedef mgOnGpu::cxtype_ref cxtype_sv_ref;
#endif

// Scalar-or-vector zeros: scalar in CUDA, vector or scalar in C++
#ifdef __CUDACC__ /* clang-format off */
inline __host__ __device__ cxtype cxzero_sv(){ return cxtype( 0, 0 ); }
#elif defined MGONGPU_CPPSIMD
inline cxtype_v cxzero_sv() { return cxtype_v(); } // RRRR=0000 IIII=0000
#else
inline cxtype cxzero_sv() { return cxtype( 0, 0 ); }
#endif /* clang-format on */

//==========================================================================

// Functions and operators for cxtype_sv
inline __host__ __device__ fptype_sv
cxabs2( const cxtype_sv& c )
{
  return cxreal( c ) * cxreal( c ) + cximag( c ) * cximag( c );
}

//==========================================================================

#endif // MGONGPUVECTORS_H
