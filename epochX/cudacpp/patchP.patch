commit a1205de1ef32642951c44bb800affa36b022de0c
Author: Andrea Valassi <andrea.valassi@cern.ch>
Date:   Sat Nov 22 19:15:49 2025 +0100

    wip dpg10k changes

diff --git a/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/CPPProcess.cc b/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/CPPProcess.cc
index 1c0266362..3605220d5 100644
--- a/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/CPPProcess.cc
+++ b/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/CPPProcess.cc
@@ -547,6 +547,27 @@ namespace mg5amcCpu
 
   //--------------------------------------------------------------------------
 
+  mgOnGpu::TimerMap2*
+  CPPProcess::pTimerMap( mgOnGpu::TimerMap2* ptr )
+  {
+    static mgOnGpu::TimerMap2* s_map = nullptr;
+    if( ptr )
+    {
+      ptr->addPartition( TIMERMAP__DEPCOUPS, "11  DEPCOUPS" );
+      ptr->addPartition( TIMERMAP__SIGMAKIN, "21  SIGMAKIN" );
+      ptr->addPartition( TIMERMAP_CALCJAMPS, "22 CALCJAMPS" );
+      ptr->addPartition( TIMERMAP__COLORSUM, "23  COLORSUM" );
+      ptr->addPartition( TIMERMAP_UPDJAMPS2, "24 UPDJAMPS2" );
+      ptr->addPartition( TIMERMAP_SELHELCOL, "25 SELHELCOL" );
+      ptr->addPartition( TIMERMAP_UPDATNEVT, "31 UPDATNEVT" );
+      ptr->addPartition( TIMERMAP___UNKNOWN, "99 ?UNKNOWN?" );
+      s_map = ptr;
+    }
+    return s_map;
+  }
+
+  //--------------------------------------------------------------------------
+
   CPPProcess::CPPProcess( bool verbose,
                           bool debug )
     : m_verbose( verbose )
@@ -1490,6 +1511,7 @@ namespace mg5amcCpu
     // Use CUDA/HIP streams to process different helicities in parallel (one good helicity per stream)
     // (1a) First, within each helicity stream, compute the QCD partial amplitudes jamp's for each helicity
     // In multichannel mode, also compute the running sums over helicities of numerators, denominators and squared jamp2s
+    if( CPPProcess::pTimerMap() ) CPPProcess::pTimerMap()->start( CPPProcess::TIMERMAP_CALCJAMPS );
     for( int ighel = 0; ighel < cNGoodHel; ighel++ )
     {
       const int ihel = cGoodHel[ighel];
@@ -1511,19 +1533,23 @@ namespace mg5amcCpu
 #endif
 #endif
     }
+    if( CPPProcess::pTimerMap() ) checkGpu( gpuDeviceSynchronize() );
 #ifdef MGONGPU_SUPPORTS_MULTICHANNEL
     // (1b) Then, in multichannel mode, also compute the running sums over helicities of squared jamp2s within each helicity stream
+    if( CPPProcess::pTimerMap() ) CPPProcess::pTimerMap()->start( CPPProcess::TIMERMAP_UPDJAMPS2 );
     for( int ighel = 0; ighel < cNGoodHel; ighel++ )
     {
       fptype* hAllJamps = ghelAllJamps + ighel * nevt; // HACK: bypass DeviceAccessJamp (consistent with layout defined there)
       gpuLaunchKernelStream( update_jamp2s, gpublocks, gputhreads, ghelStreams[ighel], hAllJamps, colAllJamp2s, cNGoodHel );
     }
 #endif
+    if( CPPProcess::pTimerMap() ) CPPProcess::pTimerMap()->start( CPPProcess::TIMERMAP__COLORSUM );
     // (2) Then compute the ME for that helicity from the color sum of QCD partial amplitudes jamps
     color_sum_gpu( ghelAllMEs, ghelAllJamps, ghelAllBlasTmp, pBlasHandle, ghelStreams, cNGoodHel, gpublocks, gputhreads );
     checkGpu( gpuDeviceSynchronize() ); // do not start helicity/color selection until the loop over helicities has completed
     // (3) Wait for all helicity streams to complete, then finally compute the ME sum over all helicities and choose one helicity and one color
     // Event-by-event random choice of helicity #403 and ME sum over helicities (defer this after the helicity loop to avoid breaking streams parallelism)
+    if( CPPProcess::pTimerMap() ) CPPProcess::pTimerMap()->start( CPPProcess::TIMERMAP_SELHELCOL );
     gpuLaunchKernel( add_and_select_hel, gpublocks, gputhreads, allselhel, allrndhel, ghelAllMEs, allMEs, gpublocks * gputhreads );
 #ifdef MGONGPU_SUPPORTS_MULTICHANNEL
     // Event-by-event random choice of color #402
@@ -1609,6 +1635,7 @@ namespace mg5amcCpu
 #endif
       for( int ighel = 0; ighel < cNGoodHel; ighel++ )
       {
+        if( CPPProcess::pTimerMap() ) CPPProcess::pTimerMap()->start( CPPProcess::TIMERMAP_CALCJAMPS );
         const int ihel = cGoodHel[ighel];
         cxtype_sv jamp_sv_1or2[nParity * ncolor] = {}; // fixed nasty bug (omitting 'nParity' caused memory corruptions after calling calculate_jamps)
 #ifdef MGONGPU_SUPPORTS_MULTICHANNEL
@@ -1617,15 +1644,18 @@ namespace mg5amcCpu
 #else
         calculate_jamps( allmomenta, allcouplings, jamp_sv_1or2, ievt00, ihel );
 #endif
+        if( CPPProcess::pTimerMap() ) CPPProcess::pTimerMap()->start( CPPProcess::TIMERMAP__COLORSUM );
         color_sum_cpu( allMEs, jamp_sv_1or2, ievt00 );
         MEs_ighel[ighel] = E_ACCESS::kernelAccess( E_ACCESS::ieventAccessRecord( allMEs, ievt00 ) );
 #if defined MGONGPU_CPPSIMD and defined MGONGPU_FPTYPE_DOUBLE and defined MGONGPU_FPTYPE2_FLOAT
         MEs_ighel2[ighel] = E_ACCESS::kernelAccess( E_ACCESS::ieventAccessRecord( allMEs, ievt00 + neppV ) );
 #endif
+        if( CPPProcess::pTimerMap() ) CPPProcess::pTimerMap()->start( CPPProcess::TIMERMAP_UPDJAMPS2 );
         for( int iParity = 0; iParity < nParity; ++iParity )
           for( int icol = 0; icol < ncolor; icol++ )
             jamp2_sv[ncolor * iParity + icol] += cxabs2( jamp_sv_1or2[ncolor * iParity + icol] ); // may underflow #831
       }
+      if( CPPProcess::pTimerMap() ) CPPProcess::pTimerMap()->start( CPPProcess::TIMERMAP_SELHELCOL );
       // Event-by-event random choice of helicity #403
       for( int ieppV = 0; ieppV < neppV; ++ieppV )
       {
diff --git a/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/CPPProcess.h b/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/CPPProcess.h
index efaf3cc67..e9bab881f 100644
--- a/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/CPPProcess.h
+++ b/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/CPPProcess.h
@@ -21,6 +21,7 @@
 
 #include "GpuAbstraction.h"
 #include "Parameters_sm.h"
+#include "timermap2.h"
 
 #include <vector>
 
@@ -64,6 +65,17 @@ namespace mg5amcCpu
     //bool verbose() const { return m_verbose; }
     bool debug() const { return m_debug; }
 
+    // HACK HACK HACK
+    static mgOnGpu::TimerMap2* pTimerMap( mgOnGpu::TimerMap2* pMap = nullptr );
+    static constexpr size_t TIMERMAP__DEPCOUPS=11;
+    static constexpr size_t TIMERMAP__SIGMAKIN=21;
+    static constexpr size_t TIMERMAP_CALCJAMPS=22;
+    static constexpr size_t TIMERMAP__COLORSUM=23;
+    static constexpr size_t TIMERMAP_UPDJAMPS2=24;
+    static constexpr size_t TIMERMAP_SELHELCOL=25;
+    static constexpr size_t TIMERMAP_UPDATNEVT=31;
+    static constexpr size_t TIMERMAP___UNKNOWN=99;
+
   public:
 
     // Process-independent compile-time constants
diff --git a/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/check_sa.cc b/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/check_sa.cc
index 98b6f23a9..aab0b14ca 100644
--- a/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/check_sa.cc
+++ b/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/check_sa.cc
@@ -305,6 +305,13 @@ main( int argc, char** argv )
     std::cout << "# iterations: " << niter << std::endl;
 
   // *** START THE NEW TIMERS ***
+  mgOnGpu::TimerMap2 timermap2;
+  mgOnGpu::TimerMap2 timermap2tot;
+  timermap2tot.addPartition( 1, "MEK::compMEs" );
+  static bool useMap2 = false;
+  const char* colortimerEnv = getenv( "CUDACPP_RUNTIME_COLORTIMER" );
+  if( colortimerEnv ) useMap2 = true;
+  if( useMap2 ) CPPProcess::pTimerMap( &timermap2 );
   mgOnGpu::TimerMap timermap;
 
   // === STEP 0 - INITIALISE
@@ -660,8 +667,12 @@ main( int argc, char** argv )
     // --- 3a. SigmaKin
     const std::string skinKey = "3a SigmaKin";
     timermap.start( skinKey );
+    timermap2tot.start( 1 );
+    if( CPPProcess::pTimerMap() ) CPPProcess::pTimerMap()->start( CPPProcess::TIMERMAP___UNKNOWN );
     constexpr bool useChannelIds = false; // TEMPORARY? disable multi-channel in check.exe and gcheck.exe #466
     pmek->computeMatrixElements( useChannelIds );
+    if( CPPProcess::pTimerMap() ) CPPProcess::pTimerMap()->stop();
+    timermap2tot.stop();
 
     // *** STOP THE NEW OLD-STYLE TIMER FOR MATRIX ELEMENTS (WAVEFUNCTIONS) ***
     wv3atime += timermap.stop(); // calc only
@@ -1226,11 +1237,16 @@ main( int argc, char** argv )
 
   // *** STOP THE NEW TIMERS ***
   timermap.stop();
+  if( useMap2 ) timermap2.stop();
   if( perf )
   {
     std::cout << std::string( SEP79, '*' ) << std::endl;
     timermap.dump();
     std::cout << std::string( SEP79, '*' ) << std::endl;
+    if( useMap2 ) timermap2.dump( "TOTALMEKCMES" );
+    if( useMap2 ) std::cout << std::string( SEP79, '*' ) << std::endl;
+    if( useMap2 ) timermap2tot.dump( "CHECKMEKCMES" );
+    if( useMap2 ) std::cout << std::string( SEP79, '*' ) << std::endl;
   }
 
   // [NB some resources like curand generators will be deleted here when stack-allocated classes go out of scope]
diff --git a/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/timer2.h b/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/timer2.h
new file mode 100644
index 000000000..fdd943cf7
--- /dev/null
+++ b/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/timer2.h
@@ -0,0 +1,209 @@
+// Copyright (C) 2020-2025 CERN and UCLouvain.
+// Licensed under the GNU Lesser General Public License (version 3 or later).
+//==========================================================================
+// Created by: S. Roiser (Feb 2020) for the MG5aMC CUDACPP plugin [old chrono timer, old API].
+// Further modified by: O. Mattelaer, S. Roiser, A. Valassi (2020-2024) for the MG5aMC CUDACPP plugin.
+//==========================================================================
+// Created by: A. Valassi (Aug 2024) for the MG5aMC CUDACPP plugin [new chrono timer, new API, add rdtsc timer].
+// Further modified by: A. Valassi (2024-2025) for the MG5aMC CUDACPP plugin.
+//==========================================================================
+
+#ifndef MGONGPUTIMER2_H
+#define MGONGPUTIMER2_H 1
+
+#include <cassert>
+#include <chrono>
+#include <iostream>
+#include <ratio>
+#include <type_traits>
+
+namespace mgOnGpu
+{
+
+  // ---------------------------------------------------------------------------
+
+  // ChronoTimer: default ("old") timers based on std::chrono clocks
+  // With respect to the original Timer class, this uses a new implementation with nanosecond counts
+  // With respect to the original Timer class, this also uses a new API with explicit start/stop
+  // Template argument T can be any of high_resolution_clock, steady_clock, system_clock
+  // See https://www.modernescpp.com/index.php/the-three-clocks
+  // See https://codereview.stackexchange.com/questions/196245/extremely-simple-timer-class-in-c
+  template<typename T>
+  class ChronoTimer
+  {
+  public:
+    ChronoTimer();
+    virtual ~ChronoTimer() {}
+    void start();
+    void stop();
+    uint64_t getCountsSinceStart() const;
+    float secondsPerCount() const; // constant throughout time
+    float getTotalDurationSeconds();
+    typedef std::nano RATIO;
+    typedef std::chrono::duration<uint64_t, RATIO> DURATION;
+    typedef std::chrono::time_point<T, DURATION> TIMEPOINT;
+  private:
+    DURATION getDurationSinceStart() const;
+    DURATION m_totalDuration;
+    bool m_started;
+    TIMEPOINT m_startTime;
+  };
+
+  template<typename T>
+  inline ChronoTimer<T>::ChronoTimer()
+    : m_totalDuration()
+    , m_started( false )
+    , m_startTime()
+  {
+    static_assert( std::is_same<T, std::chrono::high_resolution_clock>::value ||
+                   std::is_same<T, std::chrono::steady_clock>::value ||
+                   std::is_same<T, std::chrono::system_clock>::value );
+  }
+
+  template<typename T>
+  inline void
+  ChronoTimer<T>::start()
+  {
+    assert( !m_started );
+    m_started = true;
+    m_startTime = T::now();
+  }
+
+  template<typename T>
+  inline void
+  ChronoTimer<T>::stop()
+  {
+    assert( m_started );
+    m_started = false;
+    m_totalDuration += getDurationSinceStart();
+  }
+
+  template<typename T>
+  inline uint64_t
+  ChronoTimer<T>::getCountsSinceStart() const
+  {
+    return getDurationSinceStart().count();
+  }
+
+  template<typename T>
+  inline
+    typename ChronoTimer<T>::DURATION
+    ChronoTimer<T>::getDurationSinceStart() const
+  {
+    return T::now() - m_startTime;
+  }
+
+  template<typename T>
+  inline float
+  ChronoTimer<T>::secondsPerCount() const
+  {
+    return (float)RATIO::num / RATIO::den;
+  }
+
+  template<typename T>
+  inline float
+  ChronoTimer<T>::getTotalDurationSeconds()
+  {
+    assert( !m_started );
+    auto count = m_totalDuration.count();
+    return count * secondsPerCount();
+  }
+
+  // ---------------------------------------------------------------------------
+
+  // RdtscTimer: faster ("new") *EXPERIMENTAL* timers based on rdtsc
+  // The rdtsc() call is derived from the TSCNS class (https://github.com/MengRao/tscns)
+  // The conversion of rdtsc counts to seconds is calibrated on the average frequency during the timer lifetime
+  // See https://stackoverflow.com/q/76063685 and the Intel 64 and IA-32 Architectures Software Developerâ€™s Manual
+  // (https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html, June 2024):
+  // "To determine average processor clock frequency, Intel recommends the use of performance monitoring
+  // logic to count processor core clocks over the period of time for which the average is required."
+  class RdtscTimer
+  {
+  public:
+    RdtscTimer();
+    virtual ~RdtscTimer() {}
+    void start();
+    void stop();
+    uint64_t getCountsSinceStart() const;
+    float secondsPerCount(); // calibrated at this point in time
+    float getTotalDurationSeconds();
+  private:
+    static uint64_t rdtsc();
+    uint64_t m_totalDuration;
+    bool m_started;
+    uint64_t m_startCount;
+    ChronoTimer<std::chrono::high_resolution_clock> m_ctorTimer;
+    uint64_t m_ctorCount;
+  };
+
+  inline uint64_t
+  RdtscTimer::rdtsc()
+  {
+#if defined( __x86_64__ )
+#define MGONGPU_HASRDTSC 1
+    return __builtin_ia32_rdtsc();
+#else
+#undef MGONGPU_HASRDTSC
+    // RdtscTimer is only defined on Intel __x86_64__ for the moment (#977)
+    // On all other platforms, the class is defined but it is not meant to be used
+    throw std::runtime_error( "rdtsc is not defined for this platform yet" );
+#endif
+  }
+
+  inline RdtscTimer::RdtscTimer()
+    : m_totalDuration( 0 )
+    , m_started( false )
+    , m_startCount( 0 )
+    , m_ctorTimer()
+    , m_ctorCount( 0 )
+  {
+    m_ctorTimer.start();
+#ifdef MGONGPU_HASRDTSC
+    m_ctorCount = rdtsc();
+#endif
+  }
+
+  inline void
+  RdtscTimer::start()
+  {
+    assert( !m_started );
+    m_started = true;
+    m_startCount = rdtsc();
+  }
+
+  inline void
+  RdtscTimer::stop()
+  {
+    assert( m_started );
+    m_started = false;
+    m_totalDuration += getCountsSinceStart();
+  }
+
+  inline uint64_t
+  RdtscTimer::getCountsSinceStart() const
+  {
+    return rdtsc() - m_startCount;
+  }
+
+  inline float
+  RdtscTimer::secondsPerCount()
+  {
+    m_ctorTimer.stop();
+    float secPerCount = m_ctorTimer.getTotalDurationSeconds() / ( rdtsc() - m_ctorCount );
+    m_ctorTimer.start(); // allow secondsPerCount() to be called again...
+    return secPerCount;
+  }
+
+  inline float
+  RdtscTimer::getTotalDurationSeconds()
+  {
+    assert( !m_started );
+    auto count = m_totalDuration;
+    return count * secondsPerCount();
+  }
+
+  // ---------------------------------------------------------------------------
+
+}
+#endif // MGONGPUTIMER2_H
diff --git a/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/timermap2.h b/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/timermap2.h
new file mode 100644
index 000000000..cc89a5a22
--- /dev/null
+++ b/epochX/cudacpp/gg_ttgggg.dpg10000dpf10000.sa/SubProcesses/P1_Sigma_sm_gg_ttxgggg/timermap2.h
@@ -0,0 +1,163 @@
+// Copyright (C) 2020-2024 CERN and UCLouvain.
+// Licensed under the GNU Lesser General Public License (version 3 or later).
+// Created by: A. Valassi (Jul 2020) for the MG5aMC CUDACPP plugin.
+// Further modified by: O. Mattelaer, S. Roiser, A. Valassi (2020-2025) for the MG5aMC CUDACPP plugin.
+
+#ifndef MGONGPUTIMERMAP2_H
+#define MGONGPUTIMERMAP2_H 1
+
+#include <cassert>
+#include <cstdlib>
+#include <fstream>
+#include <iomanip>
+#include <map>
+#include <string>
+
+//#pragma GCC diagnostic push
+//#pragma GCC diagnostic ignored "-Wmissing-field-initializers"
+//#include "nvtx.h"
+//#pragma GCC diagnostic pop
+
+#include "timer2.h"
+#define TIMERTYPE std::chrono::high_resolution_clock
+
+namespace mgOnGpu
+{
+  class TimerMap2
+  {
+
+  public:
+
+    // Constructor
+    TimerMap2()
+      : m_chronoTimer()
+      , m_rdtscTimer()
+      , m_partitionIdToKey()
+      , m_active( 0 )
+      , m_partitionTotalCounts()
+      , m_useChronoTimers( false )
+      , m_started( false )
+    {
+#ifdef MGONGPU_HASRDTSC
+      if( getenv( "CUDACPP_RUNTIME_USECHRONOTIMERS" ) ) m_useChronoTimers = true;
+#else
+      m_useChronoTimers = true;
+#endif
+    }
+
+    // Destructor
+    virtual ~TimerMap2() {}
+
+    // Add a partition
+    void addPartition( size_t id, const std::string& key )
+    {
+      assert( id > 0 ); // id == 0 signals that no partition is active
+      assert( m_partitionIdToKey.find( id ) == m_partitionIdToKey.end() );
+      for( auto ip: m_partitionIdToKey ) assert( ip.second != key );
+      m_partitionIdToKey[id] = key;
+      m_partitionTotalCounts[id] = 0;
+    }
+
+    // Start the timer for a specific partition (key must be a non-empty string)
+    // Stop the timer for the current partition if there is one active
+    uint64_t start( size_t id )
+    {
+      assert( id > 0 );
+      //assert( m_partitionIdToKey.find( id ) != m_partitionIdToKey.end() ); // unnecessary overhead
+      // Close the previously active partition
+      uint64_t last = stop();
+      // Switch to a new partition
+      if( !m_started )
+      {
+        if( m_useChronoTimers )
+          m_chronoTimer.start();
+        else
+          m_rdtscTimer.start();
+        m_started = true;
+      }
+      m_active = id;
+      // Open a new Cuda NVTX range
+      //NVTX_PUSH( m_partitionIdToKey[id].c_str(), id ); // unnecessary overhead
+      // Return last duration
+      return last;
+    }
+
+    // Stop the timer for the current partition if there is one active
+    uint64_t stop()
+    {
+      // Close the previously active partition
+      uint64_t last = 0;
+      if( m_started )
+      {
+        if( m_useChronoTimers )
+          last = m_chronoTimer.getCountsSinceStart();
+        else
+          last = m_rdtscTimer.getCountsSinceStart();
+        m_partitionTotalCounts[m_active] += last;
+        if( m_useChronoTimers )
+          m_chronoTimer.stop();
+        else
+          m_rdtscTimer.stop();
+        m_started = false;
+      }
+      m_active = 0;
+      // Close the current Cuda NVTX range
+      //NVTX_POP(); // unnecessary overhead
+      // Return last duration
+      return last;
+    }
+
+    // Return timer calibration (at this point in time for rdtsc, constant in time for chrono)
+    float secondsPerCount()
+    {
+      if( m_useChronoTimers )
+        return m_chronoTimer.secondsPerCount();
+      else
+        return m_rdtscTimer.secondsPerCount();
+    }
+
+    // Dump the overall results
+    void dump( const std::string totalKey = "TOTAL", std::ostream& ostr = std::cout )
+    {
+      // Improve key formatting
+      size_t maxsize = 0;
+      for( auto ip: m_partitionIdToKey )
+        maxsize = std::max( maxsize, ip.second.size() );
+      maxsize = std::max( maxsize, totalKey.size() );
+      // Compute individual partition total times from partition total counts
+      std::map<std::string, float> partitionTotalTimes;
+      float secPerCount = secondsPerCount();
+      for( auto ip: m_partitionTotalCounts )
+      {
+        std::string key = m_partitionIdToKey[ip.first];
+        partitionTotalTimes[key] = m_partitionTotalCounts[ip.first] * secPerCount;
+      }
+      // Compute the overall total
+      float total = 0;
+      for( auto ip: partitionTotalTimes ) total += ip.second;
+      // Dump individual partition timers and the overall total
+      // NB: 'setw' affects only the next field (of any type)
+      ostr << std::setprecision( 6 ); // set precision (default=6): affects all floats
+      ostr << std::fixed;             // fixed format: affects all floats
+      for( auto ip: partitionTotalTimes )
+        ostr << std::setw( maxsize ) << ip.first << " : "
+             << std::setw( 12 ) << ip.second << " sec" << std::endl;
+      ostr << std::setw( maxsize ) << totalKey << " : "
+           << std::setw( 12 ) << total << " sec" << std::endl;
+      ostr << std::defaultfloat; // default format: affects all floats
+    }
+
+  private:
+
+    ChronoTimer<TIMERTYPE> m_chronoTimer;
+    RdtscTimer m_rdtscTimer;
+    std::map<size_t, std::string> m_partitionIdToKey;
+    size_t m_active;
+    std::map<size_t, uint64_t> m_partitionTotalCounts;
+    bool m_useChronoTimers;
+    bool m_started; // when the timer is stopped, it must be explicitly restarted
+  };
+
+}
+
+#endif // MGONGPUTIMERMAP2_H
